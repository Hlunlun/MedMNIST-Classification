{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5967e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\lun\\.medmnist\\pneumoniamnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\lun\\.medmnist\\pneumoniamnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\lun\\.medmnist\\pneumoniamnist.npz\n",
      "開始訓練... 使用裝置: cuda\n",
      "Epoch 1/10 - Loss: 0.2296 - Val Acc: 0.9654\n",
      "Epoch 2/10 - Loss: 0.0953 - Val Acc: 0.9714\n",
      "Epoch 3/10 - Loss: 0.0757 - Val Acc: 0.9729\n",
      "Epoch 4/10 - Loss: 0.0593 - Val Acc: 0.9684\n",
      "Epoch 5/10 - Loss: 0.0572 - Val Acc: 0.9804\n",
      "Epoch 6/10 - Loss: 0.0452 - Val Acc: 0.9774\n",
      "Epoch 7/10 - Loss: 0.0418 - Val Acc: 0.9849\n",
      "Epoch 8/10 - Loss: 0.0321 - Val Acc: 0.9834\n",
      "Epoch 9/10 - Loss: 0.0324 - Val Acc: 0.9473\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "from torchvision import transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from medmnist import PneumoniaMNIST, INFO\n",
    "\n",
    "# ==========================================\n",
    "# 1. 環境設定與超參數\n",
    "# ==========================================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_dir_tb = \"./TB_Chest\"  # 本地 TB 資料路徑\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "learning_rate = 1e-4\n",
    "num_classes = 3  # 0: Normal, 1: Pneumonia, 2: TB\n",
    "\n",
    "# ==========================================\n",
    "# 2. 資料準備：整合 MNIST 與 本地 TB 資料\n",
    "# ==========================================\n",
    "\n",
    "# A. 提取本地 TB 資料 (Label 2)\n",
    "tb_filepaths = []\n",
    "for root, dirs, files in os.walk(data_dir_tb):\n",
    "    # 只取 Tuberculosis 資料夾下的影像\n",
    "    if \"Tuberculosis\" in root:\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                tb_filepaths.append(os.path.join(root, file))\n",
    "\n",
    "tb_df = pd.DataFrame({'path': tb_filepaths, 'label': 2})\n",
    "train_tb_df, test_tb_df = train_test_split(tb_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# B. 自定義 Dataset 類別\n",
    "class MultiDiseaseDataset(Dataset):\n",
    "    def __init__(self, data_source, transform=None, is_mnist=False):\n",
    "        self.data_source = data_source\n",
    "        self.transform = transform\n",
    "        self.is_mnist = is_mnist\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_source)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_mnist:\n",
    "            # MedMNIST 回傳 (PIL Image, ndarray label)\n",
    "            img, label = self.data_source[idx]\n",
    "            img = img.convert('RGB')\n",
    "            label = int(label[0]) # 0 或 1\n",
    "        else:\n",
    "            # 本地 DF 讀取\n",
    "            img_path = self.data_source.iloc[idx]['path']\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            label = self.data_source.iloc[idx]['label'] # 2\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# C. 定義轉換 (Transforms)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# D. 建立整合數據集\n",
    "# 載入 PneumoniaMNIST (0: Normal, 1: Pneumonia)\n",
    "mnist_train = PneumoniaMNIST(split=\"train\", download=True)\n",
    "mnist_val = PneumoniaMNIST(split=\"val\", download=True)\n",
    "mnist_test = PneumoniaMNIST(split=\"test\", download=True)\n",
    "\n",
    "train_set = ConcatDataset([\n",
    "    MultiDiseaseDataset(mnist_train, transform=train_transform, is_mnist=True),\n",
    "    MultiDiseaseDataset(train_tb_df, transform=train_transform, is_mnist=False)\n",
    "])\n",
    "\n",
    "val_set = ConcatDataset([\n",
    "    MultiDiseaseDataset(mnist_val, transform=test_transform, is_mnist=True),\n",
    "    MultiDiseaseDataset(test_tb_df, transform=test_transform, is_mnist=False) # TB 用測試集一部分當驗證\n",
    "])\n",
    "\n",
    "test_set = ConcatDataset([\n",
    "    MultiDiseaseDataset(mnist_test, transform=test_transform, is_mnist=True),\n",
    "    MultiDiseaseDataset(test_tb_df, transform=test_transform, is_mnist=False)\n",
    "])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "# ==========================================\n",
    "# 3. 模型定義 (融合 main.ipynb 的架構)\n",
    "# ==========================================\n",
    "def get_model(model_name=\"convnext_tiny\"):\n",
    "    if model_name == \"convnext_tiny\":\n",
    "        model = models.convnext_tiny(weights=True)\n",
    "        # 修改最後一層為 3 類輸出\n",
    "        model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)\n",
    "    elif model_name == \"resnet50\":\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif model_name == \"vit_b_16\":\n",
    "        model = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT)\n",
    "        model.heads.head = nn.Linear(model.heads.head.in_features, num_classes)\n",
    "    return model.to(device)\n",
    "\n",
    "model = get_model(\"resnet50\") # 可切換 resnet50 或 vit_b_16\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 4. 訓練與評估函式\n",
    "# ==========================================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return correct / total, all_labels, all_preds\n",
    "\n",
    "# ==========================================\n",
    "# 5. 開始執行訓練\n",
    "# ==========================================\n",
    "print(f\"開始訓練... 使用裝置: {device}\")\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(imgs), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "    \n",
    "    val_acc, _, _ = evaluate(model, val_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {running_loss/len(train_set):.4f} - Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_fusion_model.pth\")\n",
    "\n",
    "# ==========================================\n",
    "# 6. 最終結果與混淆矩陣\n",
    "# ==========================================\n",
    "model.load_state_dict(torch.load(\"best_fusion_model.pth\"))\n",
    "acc, y_true, y_pred = evaluate(model, test_loader)\n",
    "\n",
    "print(\"\\n=== Final Test Report ===\")\n",
    "target_names = ['Normal', 'Pneumonia', 'Tuberculosis']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.title(\"Confusion Matrix: Pneumonia vs TB vs Normal\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-attention",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "